# Generative-Model-Paper

The following papers are my research interests (some papers I have recently readðŸ¥¸).

---

## Video Understanding
<!--
+ 2025.06.04 [MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos](https://arxiv.org/abs/2506.04141)
+ 2025.06.04 [Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning](https://arxiv.org/abs/2506.03525)
-->
+ 2025.06.03 [Video-XL-2](https://github.com/VectorSpaceLab/Video-XL/blob/main/Video-XL-2/README.md)
+ 2025.06.02 [ReFoCUS: Reinforcement-guided Frame Optimization for Contextual Understanding](https://arxiv.org/abs/2506.01274)
+ 2025.03.24 [Video-XL-Pro: Reconstructive Token Compression for Extremely Long Video Understanding](https://arxiv.org/abs/2503.18478)
+ 2025.01.21 [InternVideo2.5: Empowering Video MLLMs with Long and Rich Context Modeling](https://arxiv.org/abs/2501.12386)
+ 2024.12.31 [Online Video Understanding: A Comprehensive Benchmark and Memory-Augmented Method](https://arxiv.org/abs/2501.00584v1)
+ 2024.09.27 [From Seconds to Hours: Reviewing MultiModal Large Language Models on Comprehensive Long Video Understanding](https://arxiv.org/abs/2409.18938)
+ 2024.09.22 [Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding](https://arxiv.org/abs/2409.14485)
+ 2024.09.02 [TempMe: Video Temporal Token Merging for Efficient Text-Video Retrieval](https://arxiv.org/abs/2409.01156)
+ 2024.05.31 [Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis](https://arxiv.org/abs/2405.21075)
+ 2024.03.22 [InternVideo2: Scaling Foundation Models for Multimodal Video Understanding](https://arxiv.org/abs/2403.15377)
+ 2023.06.08 [Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models](https://arxiv.org/abs/2306.05424)
+ 2022.12.06 [InternVideo: General Video Foundation Models via Generative and Discriminative Learning](https://arxiv.org/abs/2212.03191)

## Video Understanding Through Visual Encoder Compression
+ 2024.04.08 [MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding](https://arxiv.org/abs/2404.05726)
+ 2024.04.04 [LongVLM: Efficient Long Video Understanding via Large Language Models](https://arxiv.org/abs/2404.03384)
+ 2023.11.28 [LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models](https://arxiv.org/abs/2311.17043)
+ 2023.07.31 [MovieChat: From Dense Token to Sparse Memory for Long Video Understanding](https://arxiv.org/abs/2307.16449)

## Test-Time Scaling (for Diffusion Model):
+ 2025.04.22 [From Reflection to Perfection: Scaling Inference-Time Optimization for Text-to-Image Diffusion Models via Reflection Tuning](https://arxiv.org/abs/2504.16080)
+ 2025.03.15 [Reflect-DiT: Inference-Time Scaling for Text-to-Image Diffusion Transformers via In-Context Reflection](https://arxiv.org/abs/2503.12271)
+ 2025.01.30 [SANA 1.5: Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer](https://arxiv.org/abs/2501.18427v2)
+ 2025.01.16 [Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps](https://arxiv.org/abs/2501.09732)
+ 2025.01.12 [A General Framework for Inference-time Scaling and Steering of Diffusion Models](https://arxiv.org/abs/2501.06848)
+ 2023.10.17 [GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment](https://arxiv.org/abs/2310.11513)

## Test-Time Scaling (for Language Model):
+ 2025.03.31 [A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?](https://arxiv.org/abs/2503.24235)
+ 2025.01.31 [SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling](https://arxiv.org/abs/2501.19306)
+ 2024.08.06 [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](https://arxiv.org/abs/2408.03314)
+ 2024.07.31 [Large Language Monkeys: Scaling Inference Compute with Repeated Sampling](https://arxiv.org/abs/2407.21787)

## Image Generation Benchmark
+ 2023.10.17 [GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment](https://arxiv.org/abs/2310.11513)
+ 2023.07.12 [T2I-CompBench: A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation](https://arxiv.org/abs/2307.06350v2)

## Few-Step Diffusion Model (T2I):
+ 2025.03.12 [SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation](https://arxiv.org/abs/2503.09641)
+ 2024.12.12 [SnapGen: Taming High-Resolution Text-to-Image Models for Mobile Devices with Efficient Architectures and Training](https://arxiv.org/abs/2412.09619)
+ 2024.12.03 [SNOOPI: Supercharged One-step Diffusion Distillation with Proper Guidance](https://arxiv.org/abs/2412.02687)
+ 2024.08 [FLUX](https://github.com/black-forest-labs/flux)
+ 2023.11.28 [SDXL-Turbo](https://stability.ai/research/adversarial-diffusion-distillation) [github](https://github.com/Stability-AI/generative-models)
+ 2023.09.30 [PixArt-Î±: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis](https://arxiv.org/abs/2310.00426)

## Few-Step Diffusion Model:
+ 2025.05.19 [Mean Flows for One-step Generative Modeling](https://arxiv.org/abs/2505.13447v1)

## Image Editing
+ 2025.05.26 [ImgEdit: A Unified Image Editing Dataset and Benchmark](https://arxiv.org/abs/2505.20275)
+ 2025.05.22 [KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models](https://arxiv.org/abs/2505.16707)
+ 2025.04.29 [In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer](https://arxiv.org/abs/2504.20690)
+ 2025.04.24 [Step1X-Edit: A Practical Framework for General Image Editing](https://arxiv.org/abs/2504.17761)
+ 2025.02.24 [KV-Edit: Training-Free Image Editing for Precise Background Preservation](https://arxiv.org/abs/2502.17363)
+ 2024.11.22 [HeadRouter: A Training-free Image Editing Framework for MM-DiTs by Adaptively Routing Attention Heads](https://arxiv.org/abs/2411.15034)
+ 2024.11.21 [Stable Flow: Vital Layers for Training-Free Image Editing](https://arxiv.org/abs/2411.14430)
+ 2024.11.07 [Taming Rectified Flow for Inversion and Editing](https://arxiv.org/abs/2501.09732)
+ 2022.08.02 [Prompt-to-Prompt Image Editing with Cross Attention Control](https://arxiv.org/abs/2208.01626)

## Diffusion Fine-Tuning through Human Feedback:
+ 2024.04.06 [Aligning Diffusion Models by Optimizing Human Utility](https://arxiv.org/abs/2404.04465)

## Noise Optimization for Diffusion Model:
+ 2024.12.05 [A Noise is Worth Diffusion Guidance](https://arxiv.org/abs/2412.03895)
+ 2024.07.19 [Not All Noises Are Created Equally:Diffusion Noise Selection and Optimization](https://arxiv.org/abs/2407.14041)
+ 2024.06.06 [ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization](https://arxiv.org/abs/2406.04312)
+ 2023.12.13 [Semantic-Driven Initial Image Construction for Guided Image Synthesis in Diffusion Model](https://arxiv.org/abs/2312.08872v1)
+ 2023.05.05 [Guided Image Synthesis via Initial Image Editing in Diffusion Model](https://arxiv.org/abs/2305.03382)
+ 2023.04.27 [Generating images of rare concepts using pre-trained diffusion models](https://arxiv.org/abs/2304.14530)

## Unified Multimodal Models:
+ 2025.04.08 [Transfer between Modalities with MetaQueries](https://arxiv.org/abs/2504.06256)
+ 2025.03.17 [Unified Autoregressive Visual Generation and Understanding with Continuous Tokens](https://arxiv.org/abs/2503.13436)

## Multimodal (Understanding):
+ 2024.09.12 [A Comprehensive Survey on Deep Multimodal Learning with Missing Modality](https://arxiv.org/abs/2409.07825v1)
+ 2021.02.26 [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) (CLIP)

## Language modelsï¼š
+ 2023.03.15 [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774) (GPT4)
+ 2022.01.26 [InstructGPT: Training Language Models to Follow Instructions with Human Feedback](https://openai.com/research/instruction-following)
+ 2020.05.28 [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) (GPT3)
+ 2019.02.14 [Language Models are Unsupervised Multitask Learners](https://openai.com/research/better-language-models) (GPT2)
+ 2018.06.11 [Improving Language Understanding by Generative Pre-Training](https://openai.com/research/language-unsupervised) (GPT)

## Language Diffusion model (Non-autoregressive Model/NAR):
+ 2025.02.14 [Large Language Diffusion Models](https://arxiv.org/pdf/2502.09992)
+ 2024.10.24 [Scaling up Masked Diffusion Models on Text](https://arxiv.org/abs/2410.18514)
+ 2024.10.23 [Scaling Diffusion Language Models via Adaptation from Autoregressive Models](https://arxiv.org/abs/2410.17891) (Adaptation)
+ 2024.06.06 [Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data](https://arxiv.org/abs/2406.03736)
+ 2023.10.25 [Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution](https://arxiv.org/abs/2310.16834) (SEDD)
+ 2023.03.12 [Diffusion Models for Non-autoregressive Text Generation: A Survey](https://arxiv.org/abs/2303.06574) (Survey)
+ 2022.11.30 [Score-based Continuous-time Discrete Diffusion Models](https://arxiv.org/abs/2211.16750) (Score-based)
+ 2022.11.02 [Concrete Score Matching: Generalized Score Matching for Discrete Data](https://arxiv.org/abs/2211.00802)
  + The first to propose concrete score for modeling discrete data.
+ 2022.05.30 [A Continuous Time Framework for Discrete Denoising Models](https://arxiv.org/abs/2205.14987) (CTMC)
  + First complete continuous time framework for discrete diffusion.
+ 2021.07.07 [Structured Denoising Diffusion Models in Discrete State-Spaces](https://arxiv.org/abs/2107.03006) (D3PM)
  + Diffusion models with discrete state spaces as a competitive model class for large scale text or image generation, however, it trains and samples the model in discrete time.

## ImageNet Generation SOTA:
+ Ranking list: https://paperswithcode.com/sota/image-generation-on-imagenet-256x256

## Diffusion model:
+ 2022.07.26 [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598) (classifier free guidance)
+ 2021.05.11 [Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233) (classifier guidance)
+ 2020.11.26 [Score-Based Generative Modeling through Stochastic Differential Equations](https://arxiv.org/abs/2011.13456)
  + Unified framework for 19's score-based method and 20's DDPM.
+ 2020.10.06 [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502) (DDIM)
+ 2020.06.19 [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) (DDPM)
+ 2019.07.12 [Generative Modeling by Estimating Gradients of the Data Distribution](https://arxiv.org/abs/1907.05600) (Score-based method)
+ 2015.03.12 [Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://arxiv.org/abs/1503.03585)

## Diffusion model for customization:
+ 2024.07.08 [Ada-adapter:Fast Few-shot Style Personlization of Diffusion Model with Pre-trained Image Encoder](https://arxiv.org/abs/2407.05552) (Ada-adapter)
+ 2023.08.13 [IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models](https://arxiv.org/abs/2308.06721) (IP-Adapter)
+ 2023.02.10 [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543) (ControlNet)
+ 2022.08.25 [DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://arxiv.org/abs/2208.12242) (DreamBooth)
+ 2022.08.02 [An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion](https://arxiv.org/abs/2208.01618) (Textual Inversion)

## Trustworthy AI

## Efficient AI:
[Survy](https://www.techrxiv.org/doi/full/10.36227/techrxiv.174785525.52679852)
+ 2023.12.06 [On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm](https://arxiv.org/abs/2312.03526) (RDED)
+ 2023.06.22 [Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective](https://arxiv.org/abs/2306.13092) (SRe2L)
+ 2022.07.20 [DC-BENCH: Dataset Condensation Benchmark](https://arxiv.org/abs/2207.09639)
+ 2022.06.29 [Beyond neural scaling laws: beating power law scaling via data pruning](https://arxiv.org/abs/2206.14486) (scaling law)
+ 2022.03.22 [Dataset Distillation by Matching Training Trajectories](https://arxiv.org/abs/2203.11932) (TM: matching trajectory)
+ 2022.03.03 [CAFE: Learning to Condense Dataset by Aligning Features](https://arxiv.org/abs/2203.01531) (matching feature)
+ 2021.10.08 [Dataset Condensation with Distribution Matching](https://arxiv.org/abs/2110.04181) (DM: matching distribution)
+ 2021.06.09 [Knowledge distillation: A good teacher is patient and consistent](https://arxiv.org/abs/2106.05237v2)
+ 2020.06.10 [Dataset Condensation with Gradient Matching](https://arxiv.org/abs/2006.05929) (DC: matching gradient)

+ 2015.03.09 [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)

## Self-Supervised learning:
+ 2020.06.13 [Bootstrap your own latent: A new approach to self-supervised Learning](https://arxiv.org/abs/2006.07733) (BYOL)

## Architecture:
Transformer/...

## Classic:
AlexNet/GAN...

---

## Code
[TinyLlama](https://github.com/jzhang38/TinyLlama)

## Blog
+ Visual Generation [zhihu](https://zhuanlan.zhihu.com/p/687092760)
+ [Language Modeling by Estimating the Ratios of the Data Distribution](https://aaronlou.com/blog/2024/discrete-diffusion/) (SEDD)

## Video
+ Score Matching [Youtube](https://www.youtube.com/watch?v=B4oHJpEJBAA) [Bilibili](https://www.bilibili.com/video/BV1h8FZeBEqj?vd_source=5519a229401f5e71a4a2b1c367c2a569)
+ Diffusion and Scored-based Generative Model (by Yang Song) [Youtube](https://www.youtube.com/watch?v=wMmqCMwuM2Q) [Bilibili](https://www.bilibili.com/video/BV1LpNweeE3q?vd_source=5519a229401f5e71a4a2b1c367c2a569)
